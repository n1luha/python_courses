{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eab6b2d",
   "metadata": {},
   "source": [
    "Переобучение присуще всем деревьям принятия решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a434749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "sns.pairplot(iris, hue='species')\n",
    "\n",
    "species_int = []\n",
    "for r in iris.values:\n",
    "    if r[4] == 'setosa':\n",
    "        species_int.append(1)\n",
    "    elif r[4] == 'versicolor':\n",
    "        species_int.append(2)\n",
    "    elif r[4] == 'virginica':\n",
    "        species_int.append(3)\n",
    "\n",
    "species_int_df = pd.DataFrame(species_int)\n",
    "print(species_int_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris[['sepal_length', 'petal_length']].copy()\n",
    "data['species'] = species_int\n",
    "\n",
    "data_versicolor = data[data['species'] == 2]\n",
    "data_virginica = data[data['species'] == 3]\n",
    "\n",
    "data_versicolor_A = data_versicolor.iloc[:25, :]\n",
    "data_versicolor_B = data_versicolor.iloc[25:, :]\n",
    "\n",
    "data_virginica_A = data_virginica.iloc[:25, :]\n",
    "data_virginica_B = data_virginica.iloc[25:, :]\n",
    "\n",
    "data_df_A = pd.concat([data_virginica_A, data_versicolor_A], ignore_index=True)\n",
    "data_df_B = pd.concat([data_virginica_B, data_versicolor_B], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc74b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_p = np.linspace(min(data['sepal_length']), max(data['sepal_length']), 100)\n",
    "x2_p = np.linspace(min(data['petal_length']), max(data['petal_length']), 100)\n",
    "\n",
    "X1_p, X2_p = np.meshgrid(x1_p, x2_p)\n",
    "\n",
    "X_p = pd.DataFrame(np.vstack([X1_p.ravel(), X2_p.ravel()]).T, columns=['sepal_length', 'petal_length'])\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, sharex='col', sharey='row')\n",
    "\n",
    "max_depth = [1, 3, 5, 7]\n",
    "\n",
    "X = data_df_A[['sepal_length', 'petal_length']]\n",
    "y = data_df_A['species']\n",
    "j = 0\n",
    "for md in max_depth:\n",
    "    model = DecisionTreeClassifier(max_depth=md)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    ax[0, j].scatter(data_virginica_A['sepal_length'], data_virginica_A['petal_length'])\n",
    "    ax[0, j].scatter(data_versicolor_A['sepal_length'], data_versicolor_A['petal_length'])\n",
    "\n",
    "    y_p = model.predict(X_p)\n",
    "\n",
    "    ax[0, j].contourf(X1_p, X2_p, y_p.reshape(X1_p.shape), alpha=0.4, levels=2, cmap='rainbow', zorder=1)\n",
    "\n",
    "    j += 1\n",
    "\n",
    "X = data_df_B[['sepal_length', 'petal_length']]\n",
    "y = data_df_B['species']\n",
    "j = 0\n",
    "for md in max_depth:\n",
    "    model = DecisionTreeClassifier(max_depth=md)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    ax[1, j].scatter(data_virginica_B['sepal_length'], data_virginica_B['petal_length'])\n",
    "    ax[1, j].scatter(data_versicolor_B['sepal_length'], data_versicolor_B['petal_length'])\n",
    "\n",
    "    y_p = model.predict(X_p)\n",
    "\n",
    "    ax[1, j].contourf(X1_p, X2_p, y_p.reshape(X1_p.shape), alpha=0.4, levels=2, cmap='rainbow', zorder=1)\n",
    "\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b19c21",
   "metadata": {},
   "source": [
    "Ансамблиевые методы. В основе идея объединения нескольких переобученных (!) моделей для уменьшения эффекта переобучения. Это называется баггинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610311c6",
   "metadata": {},
   "source": [
    "Баггинг усредняет результаты -> оптимальная классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3c5be",
   "metadata": {},
   "source": [
    "Ансамбль случайных деревьев называется случайным лесом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ea41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris[['sepal_length', 'petal_length']].copy()\n",
    "data['species'] = species_int\n",
    "\n",
    "data_setosa = data[data['species'] == 1]\n",
    "data_versicolor = data[data['species'] == 2]\n",
    "data_virginica = data[data['species'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_p = np.linspace(min(data['sepal_length']), max(data['sepal_length']), 100)\n",
    "x2_p = np.linspace(min(data['petal_length']), max(data['petal_length']), 100)\n",
    "\n",
    "X1_p, X2_p = np.meshgrid(x1_p, x2_p)\n",
    "\n",
    "X_p = pd.DataFrame(np.vstack([X1_p.ravel(), X2_p.ravel()]).T, columns=['sepal_length', 'petal_length'])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, sharex='col', sharey='row')\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].scatter(data_setosa['sepal_length'], data_setosa['petal_length'])\n",
    "    ax[i].scatter(data_versicolor['sepal_length'], data_versicolor['petal_length'])\n",
    "    ax[i].scatter(data_virginica['sepal_length'], data_virginica['petal_length'])\n",
    "\n",
    "\n",
    "\"\"\" max_depth = [1, 3, 5, 7] \"\"\"\n",
    "md = 6\n",
    "\n",
    "X = data[['sepal_length', 'petal_length']]\n",
    "y = data['species']\n",
    "\n",
    "model1 = DecisionTreeClassifier(max_depth=md)\n",
    "model1.fit(X, y)\n",
    "\n",
    "y_p1 = model1.predict(X_p)\n",
    "\n",
    "ax[0].contourf(X1_p, X2_p, y_p1.reshape(X1_p.shape), alpha=0.4, levels=2, cmap='rainbow', zorder=1)\n",
    "\n",
    "# Bagging\n",
    "\n",
    "model2 = DecisionTreeClassifier(max_depth=md)\n",
    "b = BaggingClassifier(model2, n_estimators=20, max_samples=0.5, random_state=1)\n",
    "b.fit(X, y)\n",
    "\n",
    "y_p2 = b.predict(X_p)\n",
    "\n",
    "ax[1].contourf(X1_p, X2_p, y_p2.reshape(X1_p.shape), alpha=0.4, levels=2, cmap='rainbow', zorder=1)\n",
    "\n",
    "# RandomForestClassifier\n",
    "\n",
    "model3 = RandomForestClassifier(n_estimators=20, max_samples=0.5, random_state=1)\n",
    "model3.fit(X, y)\n",
    "\n",
    "y_p3 = model3.predict(X_p)\n",
    "\n",
    "ax[2].contourf(X1_p, X2_p, y_p3.reshape(X1_p.shape), alpha=0.4, levels=2, cmap='rainbow', zorder=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "data = iris[['sepal_length', 'petal_length', 'species']].copy()\n",
    "\n",
    "data_setosa = data[data['species'] == 'setosa']\n",
    "\n",
    "x_p = pd.DataFrame(np.linspace(min(data_setosa['sepal_length']), max(data_setosa['sepal_length']), 100))\n",
    "\n",
    "X = pd.DataFrame(data_setosa['sepal_length'], columns=['sepal_length'])\n",
    "y = data_setosa['petal_length']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=20)\n",
    "model.fit(X, y)\n",
    "\n",
    "y_p = model.predict(x_p)\n",
    "\n",
    "plt.scatter(data_setosa['sepal_length'], data_setosa['petal_length'])\n",
    "plt.plot(x_p, y_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eefc70",
   "metadata": {},
   "source": [
    "Достоинства данной конструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9938db2",
   "metadata": {},
   "source": [
    "- Быстрота и простота. Распараллеливание процесса -> выигрыш во времени\n",
    "- Вероятностная классификация\n",
    "- Модель непараметрическая -> хорошо работает с задачами, где другие модели могут оказаться недообученными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c482a4",
   "metadata": {},
   "source": [
    "Недостатки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224bd74",
   "metadata": {},
   "source": [
    "- Сложно интерпретировать "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed00400",
   "metadata": {},
   "source": [
    "Метод главных компонент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4473422",
   "metadata": {},
   "source": [
    "PCA (principal component analysis) - алгоритм обучения без учителя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb6c85",
   "metadata": {},
   "source": [
    "PCA - часто используют для понижения размерности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47aa1a3",
   "metadata": {},
   "source": [
    "Задача машинного обучения без учителя состоит в выяснении зависимости между признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d9f5e",
   "metadata": {},
   "source": [
    "В PCA выполняется качественная оценка этой зависимости путем поиска главных осей координат и их использования для описания наборов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "data = iris[['petal_width', 'petal_length', 'species']].copy()\n",
    "data_v = data[data['species'] == 'versicolor']\n",
    "data_v = data_v.drop(columns=['species'])\n",
    "\n",
    "X = data_v['petal_width']\n",
    "Y = data_v['petal_length']\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "\n",
    "p = PCA(n_components=2)\n",
    "p.fit(data_v)\n",
    "\n",
    "print(p.components_)\n",
    "print(p.explained_variance_)\n",
    "print(p.mean_)\n",
    "\n",
    "plt.scatter(p.mean_[0], p.mean_[1])\n",
    "plt.plot([p.mean_[0], p.mean_[0] + p.components_[0][0] * np.sqrt(p.explained_variance_[0])], [p.mean_[1], p.mean_[1] + p.components_[0][1] * np.sqrt(p.explained_variance_[0])])\n",
    "plt.plot([p.mean_[0], p.mean_[0] + p.components_[1][0] * np.sqrt(p.explained_variance_[1])], [p.mean_[1], p.mean_[1] + p.components_[1][1] * np.sqrt(p.explained_variance_[1])])\n",
    "\n",
    "p1 = PCA(n_components=1)\n",
    "p1.fit(data_v)\n",
    "\n",
    "X_p = p1.transform(data_v)\n",
    "X_p_new = p1.inverse_transform(X_p)\n",
    "\n",
    "plt.scatter(X_p_new[:, 0], X_p_new[:, 1], alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b37ae9",
   "metadata": {},
   "source": [
    "Плюсы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6a48a",
   "metadata": {},
   "source": [
    "- Простота интерпретации\n",
    "- Эффективность в работе с многомерными данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd6552",
   "metadata": {},
   "source": [
    "Минусы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be834e7",
   "metadata": {},
   "source": [
    "- Аномальные значения в данных оказывают сильное влияние"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
